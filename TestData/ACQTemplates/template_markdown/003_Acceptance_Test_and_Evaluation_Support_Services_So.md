# 003_Acceptance_Test_and_Evaluation_Support_Services_So

_Converted from PDF using pdftotext_

## TRANSPORTATION SECURITY ADMINISTRATION
SOURCES SOUGHT NOTICE – Request for Information
Operational and Acceptance Testing Support Services (OATSS)
70T04020I9NAP6403/A00001
(Revisions in red text)
I. INTRODUCTION/PURPOSE
The Transportation Security Administration (TSA) is issuing this Sources Sought Notice
– Request for Information (RFI) to improve TSA’s understanding of market capabilities
and identify qualified vendors capable of providing Operational and Acceptance Testing
Support Services (OATSS). OATSS supports various TSA programs and respective
divisions to include Acquisition and Program Management (APM), Requirements &
Capabilities Analysis Division (RCA), Test and Evaluation Division (TED), Checked
Baggage Technology Division (CBTD) and the Checkpoint Technology Division (CTD).
Responses to this RFI will help support the acquisition strategy for this acquisition and
identify if whether or not businesses are capable of successfully providing OATSS to the
TSA.
All interested and qualified businesses (i.e., Small Business, Other than Small) are
encouraged to respond to this notice in accordance with the instructions addressed herein.
II. BACKGROUND AND OBJECTIVES
APM reports to the TSA Executive Assistant Administrator for Operations Support.

APM and RCA directly support TSA’s mission by qualifying equipment with necessary
security capabilities for deployment to the field. These offices enhance the effectiveness
and efficiency of our nation’s transportation systems through the qualification and
deployment of security capabilities that drive the global standard for security.

This notice will support TSA’s needs for Operational and Acceptance Test and
Evaluation (T&E) services in support of TSA’s acquisition programs, including screening
equipment in all modes of transportation, systems designated for Checked Baggage,
Check Point screening operations, and support of stakeholders and organizations
associated with transportation security.
Operational Testing: The OT&E support services primarily include, but are not limited to
Initial OT&Es, (IOT&E), Follow-On OT&Es (FOT&E), Operational Assessments (OA)
and Field Data Collection Activities (FDCA). The OT&E support services are

OATSS RFI: 70T04020I9NAP6403

Page 1 of 10

responsible for implementing an integrated T&E strategy including all test planning, data
collection, data analysis services, and test reporting. This T&E strategy will identify
necessary data sources, including field testing, modeling and simulation, and any other
relevant sources to ensure timely and adequately scoped evaluation processes tha
maximize use of test resources.
The OT&E support services required by multiple TSA offices and programs, including
but not limited to the:
•

•

•
•
•
•
•

Checked Baggage Technologies (CBT) Division’s Electronic Baggage
Screening Program (EBSP)
o Inline Explosive Detection Systems (EDS)
o Standalone (EDS)
Checkpoint Technologies (CPT) Division’s programs including
o Passenger Screening Program (PSP)
 Advanced Technology x-ray (carry-on baggage scanner)
 CPSS (carry-on baggage CT scanner)
 Advanced Imaging Technology (body scanner)
 Boarding Pass Scanner System
 Bottle Liquid Scanner
 Credential Authentication Technology
 Explosive Trace Detection
 Security Technology Integration Program
Air Cargo Screening Program (ACSP)
Innovation Task Force (ITF) emerging technology pilots &
demonstrations
Enterprise Business Information System Acquisitions (e.g. Financial
System Modernization)
Inspections - Red Team test events
Test and Evaluation Strategy and Planning Suppor

EBSP and PSP organize the Transportation Security Equipment (TSE) requiring OT&E
support.
The OT&E support services incorporate test planning, execution, analysis, and reporting
requirements. Generally, operational record test periods are about thirty to forty-five
calendar days for each operational test event. The operational test periods will usually
include two 8-hour shifts and operational assessment events targeted at one 8-hour shift.
Other types of field data collection activities vary widely in scope and duration,
dependent on the project’s goals and requirements.
The APM T&E Division and OT&E support services provide program and technical
management of a multi-million dollar OT&E program. The APM T&E Division
performs OT&E under Acquisition Directive 102 (AD-102) protocols for acquisition
level 1, 2 and 3 systems in real-world operational environments subject to DHS Director
Operational Test and Evaluation (DOT&E) oversight. Key processes for program
OATSS RFI: 70T04020I9NAP6403

Page 2 of 10

management support include risk management, financial management, and schedule
management.
Over the last four years, the APM T&E Division and OT&E support services have
conducted dozens of Operational Tests, Operational Assessments, and Field Data
Collection Activities at operational sites across the continental U.S., and delivering tes
plans and reports for each. Test plans include Operational Test Plans (OTP), Operational
Assessment Plans (OAP), and Data Collection Activity Plans (DCAP). Reporting
products include System Evaluation Reports (SER), Operational Assessment Reports
(OAR), and Data Collection Activity Reports (DCAR). Recommended Test Scope (RTS)
memos are also produced as needed to help establish scope of follow-up testing for
corrected system deficiencies or enhanced capabilities.
Acceptance Testing: Seeks to identify vendors that are able to acceptance testing suppor
esting for TSA technologies that are intended for the airport screening environment (both
Check Point and Checked Baggage). Includes Factory acceptance testing, Site acceptance
Testing, Operational Readiness testing and Integrated Site Acceptance testing/ Integrated
System Acceptance Testing.
Vendors will need to be capable of providing a complete solution for T&E services,
including but are not limited to:
• Develop/modify/update/maintain test procedures for standalone and inline Checked Baggage Systems.
o In-line Systems test procedures are outlined in the Planning
Guidelines and Design Standards (PGDS) for Checked Baggage
Inspection Systems.
• Develop/modify/update/maintain test procedures for Check Point Systems.
• Develop/modify/update/maintain test procedures for cyber security of all
Checked Baggage and Check Point Systems.
• Develop/modify/update/maintain test procedures for use of the American
National Standards Institute (ANSI) Test Kits. The ANSI Test Kits are
utilized and manufactured to the specifications outlined in ANSI N42.452015, American National Standard for Evaluating the Image Quality of Xray Computed Tomography (CT) Security-Screening Systems.
Note: As new technologies are employed in the systems or new
systems, new procedures will need to be developed, updated, and
maintained.
• Collect data to support various data collection efforts supporting other
divisions within TSA. Coordinate with applicable stakeholders and handle
logistics for data collection efforts.
• Provide adequate reporting (managerial and technical) to include
developing and maintaining a master schedule for all Acceptance Testing
activities.
• Develop/modify/maintain all test articles (e.g., ANSI Test Kits, Integrated
Systems Acceptance Test (ISAT) Bag Sets).

OATSS RFI: 70T04020I9NAP6403

Page 3 of 10

•
•

•
•
•
•

Maintain a data repository where all test data and reports are stored. This
repository is a back-up to the TSA Repository.
Develop a training program to maintain proficiency and train new
employees in the fundamentals of systems and also testing processes.
Ensure staff is continually trained to maintain proficiency and keep up to
he advancements of technology and evolution of procedures.
Perform system evaluations to determine methods of optimizing system
performance and also determine root cause problems on systems that are
not performing within acceptable performance criteria.
Perform system testing (Factory Acceptance Testing (FAT), Site
Acceptance Testing (SAT), Operational Readiness Testing (ORT), and/or
ISAT) for all Check Point and Checked Baggage screening equipment.
Perform ANSI CT Detection Testing on all CT Machines utilizing ANSI
42.45-2015 testing methodology. Explore and provide new methods of
esting as applicable.
Perform Network Testing on systems that are or have the ability to be
networked, including but not limited to ensuring data outputs and inputs of
different sub-systems are per design or interface requirements, ensuring
information shared at a remote displaying/analyzing station is accurate
and, ensuring data is stored according to the requirements.

As part of the Acceptance Testing program, TSA must ensure that Transportation
Security Equipment (TSE) meets TSA requirements by executing testing protocols such
as the following:
•

•

•

•
•

Factory Acceptance Testing: This test is performed at the Original
Equipment Manufacturer (OEM) location using procedures that are
established by the OEM and verified/approved by TSA. This test is
performed to ensure that systems procured by TSA meet the requirements
established in the acquisition process.
Site Acceptance Testing: This test is performed when the system is
installed in its operational location and is performed using agreed upon
est procedures between the OEM and TSA. This test shall be completed
prior to being operational.
Operational Readiness Testing: This test is performed when system
changes are required such as software or hardware, location within an
airport, major component of the system, or returning a system to operation
hat has been out of service for an extended period of time. This test is
required to be performed prior to screening live passengers or their
possession’s through the equipment.
Network Acceptance Testing (NAT): This test is performed when there is
a network component to the system. This is an on-demand type test tha
requires no specific triggers for execution.
Integrated Systems Acceptance Testing: This series of tests are performed
at various strategic times during the building and integration of the system.

OATSS RFI: 70T04020I9NAP6403

Page 4 of 10

These tests ensure that the system is secure and efficient and are
completed prior to live operation of the system.
III.

CONTRACTOR’S CAPABILITIES STATEMENT

The purpose of this RFI is for TSA to improve its understanding of market capabilities
and identify qualified vendors capable of providing OATSS. Interested vendors shall
identify their capabilities to meet the requirements as specified in sections1 – 4 below. Be
very specific when describing experience in providing similar and/or the same type work
o other Federal Agencies. A draft Statement of Work (SOW) is attached for your
reference.
Section 1 – Cover Letter
The cover letter must clearly identify the following information:
1. Company’s Name
2. Company’s Address
3. DUNS Number
4. Point of Contact(s) (Name, title, email, and phone number)
5. Identify your business size – Other than small, small, small disadvantaged, 8(a)certified small disadvantaged, HUBZone small, woman-owned small, very small,
veteran-owned small, service-disabled veteran-owned small.
6. Applicable GSA Schedule Contract No.
7. Other contract vehicles the TSA may consider for this requirement for which you
are an awardee (e.g., Government Wide Acquisition Contracts (GWACs), GSA
Schedules, DHS Strategic Sourcing Contract).
8. Potential Teaming Partners or Subcontractors.
Note: If partnerships are being suggested to completed the work, please describe wha
areas the partners will be respectively working on and provide details on the approach
and the capability.
Section 2 - Capabilities Statemen
Submit a capabilities statement that includes basic information describing the company.
The capabilities statement should also include a brief description of the company,
products, services, history, ownership, financial information, and other information
deemed relevant.
The submitted Capabilities Statement shall not exceed twenty (20) pages, in addition to a
one (1) page cover letter, for a total submission not to exceed twenty-one (21) pages.

OATSS RFI: 70T04020I9NAP6403

Page 5 of 10

Section 3 – Corporate Experience
Provide up to three examples of projects of similar in size, scope, and complexity to the
TSA requirements, preferably with the Federal Government. Briefly describe the scope
of work, to include the customer environment, application solution designed/
implemented, project management methodology, security requirements, best practices/
lessons learned, and relevant metrics (e.g., number of client sites, transaction volumes,
bandwidth availability, distance). Please also include the period of performance, total
contract value, and whether the work was performed as a prime or sub-contractor or
describe any teaming arrangements.
Section 4 – Draft Statement of Work and Technical Prompts
Based on the attached draft SOW, please describe your company's understanding of TSA
requirements, to including a general plan for how to meet TSA objectives, recommended
governance model, and organizational structure. Describe your company’s methodology
for staffing this type of requirement in terms of workforce retention, recruiting/hiring
process, personnel security, and clearance level. In terms of the draft SOW:
1. Describe capability and experience in providing programmatic and technical
management/support of a multi-million dollar testing program included but not limited
o: cost control strategies, schedule and resource management, hiring practices,
certifications, quality processes, and section 508 compliance.
2. Describe ability to provide expertise related to a broad range of scientific and
engineering disciplines to enable Operational Test & Evaluation team to verify
conformance of capabilities against operational requirements and evaluate system
Effectiveness, Suitability, and Cyber-resilience. Disciples include but not limited to:
physics, chemistry, computer science, health physicists, human factors, statistics, design
of experiments, safety, security screening operations, and engineering disciplines such as:
electrical, mechanical, materials, and structural.
3. Describe personnel training, recruitment, retention, and hiring processes tha
demonstrate ability to: provide continuity of support, response to new requirements or
capabilities and continued validation of qualified personnel to support OT&E for multiple
programs simultaneously. Individual test size can range from one (1) to over fifty (50)
est personnel and from one (1) day to over three (3) months at continental United States
locations.
4. Describe approach for accommodating immediate test team deployment with as little
as one-day notice to multiple operational sites across the country to meet urgent/emergen
data collection needs. Additionally, describe capability and experience related to the
ability to ramp-up test team to over 150 active test resources in the field at up to 15
simultaneous test sites

OATSS RFI: 70T04020I9NAP6403

Page 6 of 10

5. Describe process for managing, planning, executing, and reporting on threat inject
esting in a large variety of operational environments supporting OT&E. Up to, or more
han, 3,000 threat inject trials may be conducted per year across a large variety of
operational environments. Threat inject testing utilizes a variety of actual and simulated
hreat objects, including but not limited to explosives, weapons, and other prohibited
items, to assess system performance and support of TSA resolution procedures. The
details and configuration threat articles can be classified in nature.
6. Provide Modeling and Simulation (M&S) expertise of real-world operational
environments to include overall management, development, and maintenance of
comprehensive end-to-end security effectiveness and efficiency modeling platforms to
supplement or enhance the usefulness of live data.
7. Describe your experience and knowledge of verifying system compliance with
cybersecurity requirements and adversarial assessments which may include the
following: security compliance tools such as Nessus, Retina, nmap, and Wireshark; code
analysis through system-level testing; vulnerability assessments of the system and
interfaces; support for penetration testing based on cyber threat assessments; and analysis
of the operational impact of cybersecurity findings.
8. Describe data management procedures that allow for automated/computerized data
collection, consolidation, import, and export of up to tens of thousands data records each
day during field data collection activities. Collect, import, reduce, and produce metrics
files supporting this quantity of data daily to decision makers in support of data
authentication quality assurance, to make critical T&E strategy decisions, to facilitate
data analysis, and support development of test reports. Databases capable of supporting
he input of millions of data records, and tools required to analyze this volume of data.
9. Describe resources and technical proficiency as it relates to the scope of effort to
include the labor mix available and expertise.
10. Over the last three years, the Acceptance Testing program has supported testing of
over 17,000 pieces of equipment and 125 in-line baggage systems at numerous federal
airports. Explain how you will provide this level of testing support of TSE at factory,
laboratory and airport locations to include Check Point and Checked Baggage Systems.
11. Lifecycle and Configuration management for test articles includes development of
new test articles (to include certification, validation and maintenance), Configuration
management of test articles (to include logistics of storing and shipping) and
decommissioning. TSA has over 8,000 test articles utilized for Acceptance Testing.
Describe suggested efficiencies to minimize the test article quantities.
12. There are instances in which TSA needs to ship test articles and have them available
o test within 24 hours. Describe the logistics experience and capabilities that would
ensure shipments of the test articles to sites in these instances.

OATSS RFI: 70T04020I9NAP6403

Page 7 of 10

13. What previous experience do you have regarding testing, quality assurance, and
configuration management assessment of security or other complex equipment (related to
security equipment) prior to acceptance at production and operational milestones?
14. Describe previous experience regarding personnel and logistics resources to suppor
simultaneous tests across geographically dispersed locations, both CONUS and
OCONUS (to include surge operations). Currently, Acceptance Testing averages over
5,000 tests annually. Tests can range from one day for equipment tests to multiple weeks
phased over a year or more for the in-line baggage system tests. Describe capability and
experience in the ability to scale up resources and resource pooling, rapid response and
deployment for test events (time to test from notice of proceed to test), dedicated
resources at 100%, and maximum simultaneous testing capability.
15. Describe capability and experience in providing technical evaluations of system and
equipment test plans/procedures/reports, equipment operation/integration/installation
manuals, equipment configuration item lists, and engineering changes.
16. Describe capability and experience of providing training program developmen
services. As technology changes it will be imperative that a robust training program be in
place to support the changes in technology (i.e., MIT, ICS).
17. Describe capability and experience in performing cyber testing and the ability to
adapt a new and upcoming cyber requirements. Describe test capability and expertise in
cyber testing for non-screening and screening systems.
18. Acceptance testing will be required to perform different types of cyber testing that are
not yet entirely defined; however, TSA seeks to understand your capabilities regarding
he two general areas below.
i. Cyber testing capability for Transportation Security Equipment (e.g.,
vulnerability testing, Operating System (OS) hardening test, etc.).
ii. Cyber testing capability for Baggage Handling Systems (BHS);
elements of cyber requirements for BHS are in Section 12 of PGDS version 6.
19. Describe capability and experience to test and evaluate TSE networks.
20. Interconnected systems testing: One or more technologies in checkpoint or check
baggage connected together to provide a final security decision. Describe capability and
experience to perform testing of interconnected system.
21. Remote Testing: Describe capability and experience to develop and execute a remote
esting capability where significant cost savings are achieved by leveraging technology.
22. Virtual Test/Simulated Test: Describe capability and experience to develop and
execute virtual or simulated tests.

OATSS RFI: 70T04020I9NAP6403

Page 8 of 10

23. Describe the capability to support operational and acceptance missions
simultaneously. Use the information above to determine metrics and total of tests and
effort that may need to be supported.
Section 5 – Technical Exchanges
TSA will hold thirty (30) minute Technical Exchanges with interested vendors to allow
he Government to provide valuable information and responses to industry questions
regarding this potential requirement. The agenda will consist of an overview of the scope
of work, potential acquisition strategy and a question and answer session. These
exchanges will take place between March 11 – 12, 2020 and can be held in person or via
a Webinar.
Interested vendors should submit two (2) available time slots between 9:00AM Eastern
Standard Time (EST) – 2:30PM, EST during this time period as well as preference of inperson or webinar, no later than March 6, 2020 at 3:00PM. Those vendors interested in an
in-person meeting shall provide a password protected Excel spreadsheet with the Name,
Date of Birth and Social Security Number of those attending, limited to no more than
hree (3) attendees. Vendors will be notified of their scheduled meetings no later than
March 9, 2020 at 3:00PM.
IV.

SUBMISSION OF INFORMATION

The information requested in support of the Capabilities Statement must be submitted in
writing. The submitted Capabilities Statement shall not exceed twenty (20) pages, in
addition to a one (1) page cover letter, for a total submission not to exceed twenty-one
(21) pages.
Your submission should be organized in accordance with the instructions in this
document in order to permit a thorough and accurate review and evaluation by the TSA.
Responses to this RFI must be submitted to the TSA via electronic mail no later than
March 30, 2020 at 10:00AM, EST to the following:
Siobhan Lawson at Siobhan.Lawson@tsa.dhs.gov
Aaron Lewis at Aaron.J.Lewis@tsa.dhs.gov
Sam Heim at Sam.Heim1@tsa.dhs.gov
Responses not received by the closing date and time may not be considered or evaluated
by the TSA.
V.

POINTS OF CONTACT

All comments, inquiries and responses should be directed to the following individuals:
Siobhan Lawson
Contract Specialis

OATSS RFI: 70T04020I9NAP6403

Page 9 of 10

Siobhan.lawson@tsa.dhs.gov
Aaron Lewis
Contract Specialis
Aaron.J.Lewis@tsa.dhs.gov
VI.

DISCLAIMER

THIS REQUEST FOR INFORMATION IS SOLELY FOR INFORMATIONAL AND
PLANNING PURPOSES AND DOES NOT CONSTITUTE A SOLICITATION. In
accordance with FAR 15.201(e), responses to this notice are not offers and cannot be
accepted by the Government to form a binding contract, nor do they affect a potential
offeror's ability to respond to any future synopsis/solicitation, which may or may not follow
or restrict the Government's eventual acquisition approach. The Government will no
provide reimbursement for any information that may be submitted in response to this
notice, and no basis for a claim against the Government shall arise from a response to this
notice or Government use of any information provided. Respondents are solely responsible
for all expenses associated with responding to this RFI.

OATSS RFI: 70T04020I9NAP6403

Page 10 of 10

